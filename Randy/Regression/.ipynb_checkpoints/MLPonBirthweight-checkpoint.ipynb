{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INST</th>\n",
       "      <th>RPLACE</th>\n",
       "      <th>RCOUNTY</th>\n",
       "      <th>PLURAL</th>\n",
       "      <th>BDATE</th>\n",
       "      <th>BMONTH</th>\n",
       "      <th>BDAY</th>\n",
       "      <th>BYEAR</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RACE</th>\n",
       "      <th>...</th>\n",
       "      <th>MOTHERTR</th>\n",
       "      <th>IANEMIA</th>\n",
       "      <th>BINJURY</th>\n",
       "      <th>FAS</th>\n",
       "      <th>HYALINE</th>\n",
       "      <th>ASPIRATE</th>\n",
       "      <th>VENTLESS</th>\n",
       "      <th>VENTMORE</th>\n",
       "      <th>ISEIZURE</th>\n",
       "      <th>OTHINF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6800</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4100</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133417</th>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-12-19</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133418</th>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-12-22</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133419</th>\n",
       "      <td>1</td>\n",
       "      <td>2600</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-12-26</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133420</th>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-12-30</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133421</th>\n",
       "      <td>1</td>\n",
       "      <td>8100</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133422 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        INST  RPLACE  RCOUNTY  PLURAL       BDATE  BMONTH  BDAY  BYEAR  SEX  \\\n",
       "0          1    6800       68       1  2008-01-01       1     1   2008    2   \n",
       "1          1     160        1       1  2008-01-02       1     2   2008    2   \n",
       "2          1     190        1       1  2008-01-02       1     2   2008    1   \n",
       "3          1    4100       41       1  2008-01-03       1     3   2008    2   \n",
       "4          1     160        1       1  2008-01-03       1     3   2008    2   \n",
       "...      ...     ...      ...     ...         ...     ...   ...    ...  ...   \n",
       "133417     1    2000       20       1  2008-12-19      12    19   2008    1   \n",
       "133418     1    2000       20       1  2008-12-22      12    22   2008    2   \n",
       "133419     1    2600       26       1  2008-12-26      12    26   2008    1   \n",
       "133420     1    2000       20       1  2008-12-30      12    30   2008    2   \n",
       "133421     1    8100       81       1  2008-12-31      12    31   2008    1   \n",
       "\n",
       "        RACE  ...  MOTHERTR  IANEMIA  BINJURY  FAS  HYALINE  ASPIRATE  \\\n",
       "0          1  ...         2        0        0    0        0         0   \n",
       "1          2  ...         2        0        0    0        0         0   \n",
       "2          1  ...         2        0        0    0        0         0   \n",
       "3          1  ...         2        0        0    0        0         0   \n",
       "4          1  ...         2        0        0    0        0         0   \n",
       "...      ...  ...       ...      ...      ...  ...      ...       ...   \n",
       "133417     1  ...         2        9        9    9        9         9   \n",
       "133418     1  ...         2        9        9    9        9         9   \n",
       "133419     1  ...         2        9        9    9        9         9   \n",
       "133420     1  ...         2        9        9    9        9         9   \n",
       "133421     0  ...         2        9        9    9        9         9   \n",
       "\n",
       "        VENTLESS  VENTMORE  ISEIZURE  OTHINF  \n",
       "0              0         0         0       0  \n",
       "1              0         0         0       0  \n",
       "2              0         0         0       0  \n",
       "3              0         0         0       0  \n",
       "4              0         0         0       0  \n",
       "...          ...       ...       ...     ...  \n",
       "133417         9         9         9       9  \n",
       "133418         9         9         9       9  \n",
       "133419         9         9         9       9  \n",
       "133420         9         9         9       9  \n",
       "133421         9         9         9       9  \n",
       "\n",
       "[133422 rows x 125 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"2008_births-Copy1.csv\")\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BPOUND</th>\n",
       "      <th>BOUNCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133417</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133418</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133419</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133420</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133421</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133422 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        BPOUND  BOUNCE\n",
       "0            4       1\n",
       "1            8       3\n",
       "2            9       0\n",
       "3            7       6\n",
       "4            9       7\n",
       "...        ...     ...\n",
       "133417       6       8\n",
       "133418       9       2\n",
       "133419       8       7\n",
       "133420       5      13\n",
       "133421       7       3\n",
       "\n",
       "[133422 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#birthweight is what we want to predict - change this to single target \n",
    "birth_weight = data[['BPOUND', 'BOUNCE']] \n",
    "birth_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA might be a good technique to select predictors \n",
    "\n",
    "#note that PCA performs best when data is normalized (range b/w 0 and 1)\n",
    "\n",
    "#It is possible to use categorical and continuous predictors \n",
    "#for a regression problem. My understanding is you need to make \n",
    "#dummy variables for the binary predictors. \n",
    "\n",
    "#Variables that we will need to deal with: \n",
    "# BDATE, HISPMOM, HISPDAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attempting PCA on data\n",
    "#for now I drop the BDATE, HISPMOM AND HISPDAD\n",
    "data_drop = data.drop([\"BDATE\", \"HISPMOM\", \"HISPDAD\", \"BOUNCE\", \"BPOUND\"], axis = 1) #axis = 1 means to drop column not row\n",
    "data_drop=data_drop.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a list of columns in pandas object \n",
    "names_of_data = data_drop.columns.tolist()\n",
    "\n",
    "#shuffle = false prevents data split being different everytime\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_drop, birth_weight, test_size = 0.2, shuffle = False)\n",
    "\n",
    "#split test into validate and test, again making sure the data is always the same for consistency\n",
    "#X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.25, shuffle = False)\n",
    "\n",
    "#Normalizing the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "\n",
    "#running the actual PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "#relief f algorithm - sorting features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "[3.89856404e-02 3.41089470e-02 3.05310536e-02 2.86690661e-02\n",
      " 2.39828710e-02 2.07124228e-02 1.81565355e-02 1.70798239e-02\n",
      " 1.68763289e-02 1.59961073e-02 1.56220702e-02 1.35585642e-02\n",
      " 1.30251204e-02 1.13087563e-02 1.10457470e-02 1.09427186e-02\n",
      " 1.06522571e-02 1.03091115e-02 1.02034145e-02 1.01603763e-02\n",
      " 9.98586972e-03 9.86404012e-03 9.78778404e-03 9.61165628e-03\n",
      " 9.46902421e-03 9.40630729e-03 9.25092446e-03 9.20797437e-03\n",
      " 9.16882901e-03 9.11728971e-03 9.08471022e-03 9.05880935e-03\n",
      " 8.91090184e-03 8.85632587e-03 8.83902308e-03 8.82366452e-03\n",
      " 8.73228213e-03 8.70972804e-03 8.64475483e-03 8.63888132e-03\n",
      " 8.60300393e-03 8.57402898e-03 8.54542908e-03 8.51710741e-03\n",
      " 8.50298288e-03 8.46111398e-03 8.42122923e-03 8.39505222e-03\n",
      " 8.37548109e-03 8.34046815e-03 8.29732609e-03 8.28947627e-03\n",
      " 8.24895028e-03 8.22904830e-03 8.20238682e-03 8.12690154e-03\n",
      " 8.11341630e-03 8.08291392e-03 8.07851589e-03 8.03763212e-03\n",
      " 8.01473052e-03 7.96613523e-03 7.90999598e-03 7.89944166e-03\n",
      " 7.83600377e-03 7.82191448e-03 7.78512254e-03 7.75691445e-03\n",
      " 7.69956508e-03 7.66449230e-03 7.60968558e-03 7.58920895e-03\n",
      " 7.51965207e-03 7.50072699e-03 7.41546041e-03 7.36057792e-03\n",
      " 7.17224177e-03 7.11636014e-03 7.01568819e-03 6.99311496e-03\n",
      " 6.88970752e-03 6.80287045e-03 6.71667348e-03 6.59331242e-03\n",
      " 6.56011619e-03 6.39097514e-03 6.21038587e-03 6.13263995e-03\n",
      " 6.02101475e-03 5.88755078e-03 5.62716616e-03 5.49427350e-03\n",
      " 5.42691648e-03 5.30849077e-03 5.16759622e-03 4.77164460e-03\n",
      " 4.64430993e-03 4.52817477e-03 4.35785968e-03 4.10170975e-03\n",
      " 3.95902522e-03 3.70091254e-03 3.10259706e-03 2.89941030e-03\n",
      " 2.48400831e-03 1.79876640e-03 1.72329185e-03 9.56485073e-04\n",
      " 9.01290670e-04 6.15880756e-04 5.54770674e-04 2.94096489e-04\n",
      " 1.90827613e-04 3.83559595e-08 7.68856124e-33 2.96807199e-33\n",
      " 9.98109174e-34 9.84374599e-34 4.90840852e-34 2.29359132e-35]\n"
     ]
    }
   ],
   "source": [
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(len(explained_variance))\n",
    "print(explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we can see, there are components that contribute nearly zero variance. Let's get rid of them to speed up computation\n",
    "#time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 114)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#add up pounds and ounces\n",
    "\n",
    "y_train = y_train['BPOUND'] + y_train['BOUNCE']*0.0625\n",
    "y_test = y_test['BPOUND'] + y_test['BOUNCE']*0.0625\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 7.39397411\n",
      "Validation score: 0.739779\n",
      "Iteration 2, loss = 0.60325827\n",
      "Validation score: 0.838932\n",
      "Iteration 3, loss = 0.39093877\n",
      "Validation score: 0.874129\n",
      "Iteration 4, loss = 0.29075384\n",
      "Validation score: 0.899946\n",
      "Iteration 5, loss = 0.23499335\n",
      "Validation score: 0.894197\n",
      "Iteration 6, loss = 0.19359896\n",
      "Validation score: 0.935642\n",
      "Iteration 7, loss = 0.15921753\n",
      "Validation score: 0.936279\n",
      "Iteration 8, loss = 0.13365026\n",
      "Validation score: 0.951918\n",
      "Iteration 9, loss = 0.12100875\n",
      "Validation score: 0.944566\n",
      "Iteration 10, loss = 0.11584606\n",
      "Validation score: 0.949051\n",
      "Iteration 11, loss = 0.10391040\n",
      "Validation score: 0.956184\n",
      "Iteration 12, loss = 0.08678295\n",
      "Validation score: 0.967101\n",
      "Iteration 13, loss = 0.08351694\n",
      "Validation score: 0.965701\n",
      "Iteration 14, loss = 0.07472547\n",
      "Validation score: 0.971957\n",
      "Iteration 15, loss = 0.07185398\n",
      "Validation score: 0.967977\n",
      "Iteration 16, loss = 0.07465275\n",
      "Validation score: 0.964654\n",
      "Iteration 17, loss = 0.06931703\n",
      "Validation score: 0.970958\n",
      "Iteration 18, loss = 0.06658553\n",
      "Validation score: 0.968042\n",
      "Iteration 19, loss = 0.06413716\n",
      "Validation score: 0.974434\n",
      "Iteration 20, loss = 0.06617278\n",
      "Validation score: 0.971747\n",
      "Iteration 21, loss = 0.06527556\n",
      "Validation score: 0.973906\n",
      "Iteration 22, loss = 0.06004058\n",
      "Validation score: 0.976752\n",
      "Iteration 23, loss = 0.05680856\n",
      "Validation score: 0.975700\n",
      "Iteration 24, loss = 0.05685874\n",
      "Validation score: 0.976220\n",
      "Iteration 25, loss = 0.05692659\n",
      "Validation score: 0.978327\n",
      "Iteration 26, loss = 0.05626765\n",
      "Validation score: 0.976676\n",
      "Iteration 27, loss = 0.05758623\n",
      "Validation score: 0.978616\n",
      "Iteration 28, loss = 0.05662055\n",
      "Validation score: 0.978925\n",
      "Iteration 29, loss = 0.05422035\n",
      "Validation score: 0.976358\n",
      "Iteration 30, loss = 0.05879075\n",
      "Validation score: 0.978162\n",
      "Iteration 31, loss = 0.05508978\n",
      "Validation score: 0.979523\n",
      "Iteration 32, loss = 0.05259472\n",
      "Validation score: 0.976074\n",
      "Iteration 33, loss = 0.05388478\n",
      "Validation score: 0.979302\n",
      "Iteration 34, loss = 0.05157425\n",
      "Validation score: 0.975924\n",
      "Iteration 35, loss = 0.05221130\n",
      "Validation score: 0.976341\n",
      "Iteration 36, loss = 0.05159047\n",
      "Validation score: 0.979436\n",
      "Iteration 37, loss = 0.05416639\n",
      "Validation score: 0.979823\n",
      "Iteration 38, loss = 0.05466066\n",
      "Validation score: 0.978611\n",
      "Iteration 39, loss = 0.05542917\n",
      "Validation score: 0.979924\n",
      "Iteration 40, loss = 0.05484083\n",
      "Validation score: 0.979412\n",
      "Iteration 41, loss = 0.05090447\n",
      "Validation score: 0.980550\n",
      "Iteration 42, loss = 0.05035253\n",
      "Validation score: 0.980269\n",
      "Iteration 43, loss = 0.05035950\n",
      "Validation score: 0.979699\n",
      "Iteration 44, loss = 0.05169858\n",
      "Validation score: 0.980158\n",
      "Iteration 45, loss = 0.05118778\n",
      "Validation score: 0.979804\n",
      "Iteration 46, loss = 0.05227509\n",
      "Validation score: 0.979346\n",
      "Iteration 47, loss = 0.05141100\n",
      "Validation score: 0.979895\n",
      "Iteration 48, loss = 0.05048863\n",
      "Validation score: 0.980160\n",
      "Iteration 49, loss = 0.05112890\n",
      "Validation score: 0.980508\n",
      "Iteration 50, loss = 0.05224016\n",
      "Validation score: 0.980793\n",
      "Iteration 51, loss = 0.04972908\n",
      "Validation score: 0.980269\n",
      "Iteration 52, loss = 0.04922295\n",
      "Validation score: 0.980989\n",
      "Iteration 53, loss = 0.04993424\n",
      "Validation score: 0.980609\n",
      "Iteration 54, loss = 0.04923228\n",
      "Validation score: 0.981240\n",
      "Iteration 55, loss = 0.04839532\n",
      "Validation score: 0.980947\n",
      "Iteration 56, loss = 0.04910781\n",
      "Validation score: 0.980244\n",
      "Iteration 57, loss = 0.04996892\n",
      "Validation score: 0.977014\n",
      "Iteration 58, loss = 0.05820466\n",
      "Validation score: 0.981108\n",
      "Iteration 59, loss = 0.04944871\n",
      "Validation score: 0.981133\n",
      "Iteration 60, loss = 0.04875157\n",
      "Validation score: 0.981090\n",
      "Iteration 61, loss = 0.04882538\n",
      "Validation score: 0.981372\n",
      "Iteration 62, loss = 0.04876063\n",
      "Validation score: 0.980929\n",
      "Iteration 63, loss = 0.04876368\n",
      "Validation score: 0.981552\n",
      "Iteration 64, loss = 0.04870793\n",
      "Validation score: 0.980915\n",
      "Iteration 65, loss = 0.04943520\n",
      "Validation score: 0.981699\n",
      "Iteration 66, loss = 0.04901168\n",
      "Validation score: 0.981403\n",
      "Iteration 67, loss = 0.04957199\n",
      "Validation score: 0.980978\n",
      "Iteration 68, loss = 0.04879549\n",
      "Validation score: 0.981541\n",
      "Iteration 69, loss = 0.04864286\n",
      "Validation score: 0.981195\n",
      "Iteration 70, loss = 0.04948751\n",
      "Validation score: 0.981343\n",
      "Iteration 71, loss = 0.04988619\n",
      "Validation score: 0.981220\n",
      "Iteration 72, loss = 0.04875464\n",
      "Validation score: 0.981545\n",
      "Iteration 73, loss = 0.04924372\n",
      "Validation score: 0.981776\n",
      "Iteration 74, loss = 0.04796909\n",
      "Validation score: 0.981567\n",
      "Iteration 75, loss = 0.04817263\n",
      "Validation score: 0.980532\n",
      "Iteration 76, loss = 0.04835028\n",
      "Validation score: 0.981484\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(early_stopping=True, hidden_layer_sizes=30, max_iter=150,\n",
       "             random_state=1, verbose='True')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets use MLP (Multilayer Perceptron)\n",
    "\n",
    "from sklearn import neighbors\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "regressor = MLPRegressor(random_state = 1, max_iter = 150, hidden_layer_sizes=30, solver='adam', early_stopping = True, validation_fraction = 0.1, verbose ='True')\n",
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = regressor.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9130445861531262"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26685\n"
     ]
    }
   ],
   "source": [
    "x_vector = np.linspace(0, len(X_test),26685 )\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = range(100)\n",
    "y = range(100,200)\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "ax1.scatter(x_vector, predicted_y,s= 10, c='b', marker=\"s\", label='Predicted')\n",
    "ax1.scatter(x_vector, y_test, s = 3, c='r', marker=\"o\", label='Target')\n",
    "plt.legend(loc='lower left');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we can see the model fail to classify the data at the end of the dataset "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
