{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data = pd.read_csv(\"Data/2008_births.csv\")\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#birthweight is what we want to predict - change this to single target \n",
    "birth_weight = data[['BPOUND', 'BOUNCE']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA might be a good technique to select predictors \n",
    "\n",
    "#note that PCA performs best when data is normalized (range b/w 0 and 1)\n",
    "\n",
    "#It is possible to use categorical and continuous predictors \n",
    "#for a regression problem. My understanding is you need to make \n",
    "#dummy variables for the binary predictors. \n",
    "\n",
    "#Variables that we will need to deal with: \n",
    "# BDATE, HISPMOM, HISPDAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attempting PCA on data\n",
    "#for now I drop the BDATE, HISPMOM AND HISPDAD\n",
    "data_drop = data.drop([\"BDATE\", \"HISPMOM\", \"HISPDAD\", \"BOUNCE\", \"BPOUND\"], axis = 1) #axis = 1 means to drop column not row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a list of columns in pandas object \n",
    "names_of_data = data_drop.columns.tolist()\n",
    "\n",
    "#shuffle = false prevents data split being different everytime\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_drop, birth_weight, test_size = 0.2, shuffle = False)\n",
    "\n",
    "#split test into validate and test, again making sure the data is always the same for consistency\n",
    "#X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.25, shuffle = False)\n",
    "\n",
    "#Normalizing the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "#running the actual PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "#relief f algorithm - sorting features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(len(explained_variance))\n",
    "print(explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explained variance prints the variance each principal component contributes.\n",
    "#As we can see, the last 5 contribute very little (maybe we can get rid of?)\n",
    "\n",
    "#We also want to check for linearity between the input predictors and the output \n",
    "#If there is high colinearity, then we want to use ridge regression - A variant of lin regression that has regulatization\n",
    "\n",
    "#Correlation indicates strength and direction of a linear relationship. let's use this on the predictors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train[\"BPOUND\"]+y_train[\"BOUNCE\"]*0.0625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test [\"BPOUND\"]+y_test[\"BOUNCE\"]*0.0625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hibamahmood/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-e31f6a059b3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1531\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[1;32m   1532\u001b[0m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0;32m-> 1533\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1534\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    167\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    168\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X_train,y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106737, 120)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106737, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BPOUND</th>\n",
       "      <th>BOUNCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133392</th>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133393</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133394</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133395</th>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133396</th>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133397</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133398</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133399</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133400</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133401</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133402</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133403</th>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133404</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133405</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133406</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133407</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133408</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133409</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133410</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133411</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133412</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133413</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133414</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133415</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133416</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133417</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133418</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133419</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133420</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133421</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133422 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        BPOUND  BOUNCE\n",
       "0            4       1\n",
       "1            8       3\n",
       "2            9       0\n",
       "3            7       6\n",
       "4            9       7\n",
       "5            6       8\n",
       "6            5       8\n",
       "7            5       2\n",
       "8            4      15\n",
       "9            7       4\n",
       "10           8       9\n",
       "11           6      12\n",
       "12           6       4\n",
       "13           6      15\n",
       "14           7       7\n",
       "15           7      13\n",
       "16           8       3\n",
       "17           6       1\n",
       "18           5      12\n",
       "19           7       1\n",
       "20           7       4\n",
       "21           4       7\n",
       "22           5       7\n",
       "23           8       5\n",
       "24           6      15\n",
       "25           7       2\n",
       "26           7      14\n",
       "27           7      14\n",
       "28           8       9\n",
       "29           7      13\n",
       "...        ...     ...\n",
       "133392       6      12\n",
       "133393       6       0\n",
       "133394       7       4\n",
       "133395       7      11\n",
       "133396       8      12\n",
       "133397       7       6\n",
       "133398       6       8\n",
       "133399       7       8\n",
       "133400       5      10\n",
       "133401       7       6\n",
       "133402       6       5\n",
       "133403       8      12\n",
       "133404       6       1\n",
       "133405       7       8\n",
       "133406       7       4\n",
       "133407       7       5\n",
       "133408       4      10\n",
       "133409       8       4\n",
       "133410       3       8\n",
       "133411       6       9\n",
       "133412       7       0\n",
       "133413       5      10\n",
       "133414       7      14\n",
       "133415       7       1\n",
       "133416       7       9\n",
       "133417       6       8\n",
       "133418       9       2\n",
       "133419       8       7\n",
       "133420       5      13\n",
       "133421       7       3\n",
       "\n",
       "[133422 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birth_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=7, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=7,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                      n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-17.37668074387162"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 20)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test,y_predict)\n",
    "plt.xlim(0, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
