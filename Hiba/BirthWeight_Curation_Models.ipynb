{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "BirthWeight_Curation_Models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca5qFCN7MvRe"
      },
      "source": [
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "data = pd.read_csv(\"2008_births.csv\")\n",
        "data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M8Yhei4MvRg"
      },
      "source": [
        "import numpy as np \n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66M1eUjRMvRh"
      },
      "source": [
        "#birthweight is what we want to predict - change this to single target \n",
        "birth_weight = data[['BPOUND', 'BOUNCE']] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NOkzXSgMvRh"
      },
      "source": [
        "#PCA might be a good technique to select predictors \n",
        "\n",
        "#note that PCA performs best when data is normalized (range b/w 0 and 1)\n",
        "\n",
        "#It is possible to use categorical and continuous predictors \n",
        "#for a regression problem. My understanding is you need to make \n",
        "#dummy variables for the binary predictors. \n",
        "\n",
        "#Variables that we will need to deal with: \n",
        "# BDATE, HISPMOM, HISPDAD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFGHanPsMvRi"
      },
      "source": [
        "#Attempting PCA on data\n",
        "#for now I drop the BDATE, HISPMOM AND HISPDAD\n",
        "data_drop = data.drop([\"BDATE\", \"HISPMOM\", \"HISPDAD\", \"BOUNCE\", \"BPOUND\"], axis = 1) #axis = 1 means to drop column not row"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrXh3ThZMvRi"
      },
      "source": [
        "#get a list of columns in pandas object \n",
        "names_of_data = data_drop.columns.tolist()\n",
        "\n",
        "#shuffle = false prevents data split being different everytime\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_drop, birth_weight, test_size = 0.2, shuffle = False)\n",
        "\n",
        "#split test into validate and test, again making sure the data is always the same for consistency\n",
        "#X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.25, shuffle = False)\n",
        "\n",
        "#Normalizing the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "#running the actual PCA\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA()\n",
        "X_train = pca.fit_transform(X_train)\n",
        "X_test = pca.transform(X_test)\n",
        "\n",
        "#relief f algorithm - sorting features "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrfrOPUVMvRi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18e4f6a2-94cc-496f-c175-7ea8c7fa3557"
      },
      "source": [
        "explained_variance = pca.explained_variance_ratio_\n",
        "print(len(explained_variance))\n",
        "print(explained_variance)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "120\n",
            "[3.89856404e-02 3.41089470e-02 3.05310536e-02 2.86690661e-02\n",
            " 2.39828710e-02 2.07124228e-02 1.81565355e-02 1.70798239e-02\n",
            " 1.68763289e-02 1.59961073e-02 1.56220702e-02 1.35585642e-02\n",
            " 1.30251204e-02 1.13087563e-02 1.10457470e-02 1.09427186e-02\n",
            " 1.06522571e-02 1.03091115e-02 1.02034145e-02 1.01603763e-02\n",
            " 9.98586972e-03 9.86404012e-03 9.78778404e-03 9.61165628e-03\n",
            " 9.46902421e-03 9.40630729e-03 9.25092446e-03 9.20797437e-03\n",
            " 9.16882901e-03 9.11728971e-03 9.08471022e-03 9.05880935e-03\n",
            " 8.91090184e-03 8.85632587e-03 8.83902308e-03 8.82366452e-03\n",
            " 8.73228213e-03 8.70972804e-03 8.64475483e-03 8.63888132e-03\n",
            " 8.60300393e-03 8.57402898e-03 8.54542908e-03 8.51710741e-03\n",
            " 8.50298288e-03 8.46111398e-03 8.42122923e-03 8.39505222e-03\n",
            " 8.37548109e-03 8.34046815e-03 8.29732609e-03 8.28947627e-03\n",
            " 8.24895028e-03 8.22904830e-03 8.20238682e-03 8.12690154e-03\n",
            " 8.11341630e-03 8.08291392e-03 8.07851589e-03 8.03763212e-03\n",
            " 8.01473052e-03 7.96613523e-03 7.90999598e-03 7.89944166e-03\n",
            " 7.83600377e-03 7.82191448e-03 7.78512254e-03 7.75691445e-03\n",
            " 7.69956508e-03 7.66449230e-03 7.60968558e-03 7.58920895e-03\n",
            " 7.51965207e-03 7.50072699e-03 7.41546041e-03 7.36057792e-03\n",
            " 7.17224177e-03 7.11636014e-03 7.01568819e-03 6.99311496e-03\n",
            " 6.88970752e-03 6.80287045e-03 6.71667348e-03 6.59331242e-03\n",
            " 6.56011619e-03 6.39097514e-03 6.21038587e-03 6.13263995e-03\n",
            " 6.02101475e-03 5.88755078e-03 5.62716616e-03 5.49427350e-03\n",
            " 5.42691648e-03 5.30849077e-03 5.16759622e-03 4.77164460e-03\n",
            " 4.64430993e-03 4.52817477e-03 4.35785968e-03 4.10170975e-03\n",
            " 3.95902522e-03 3.70091254e-03 3.10259706e-03 2.89941030e-03\n",
            " 2.48400831e-03 1.79876640e-03 1.72329185e-03 9.56485073e-04\n",
            " 9.01290670e-04 6.15880756e-04 5.54770674e-04 2.94096489e-04\n",
            " 1.90827613e-04 3.83559595e-08 7.68856124e-33 2.96807199e-33\n",
            " 9.98109174e-34 9.84374599e-34 4.90840852e-34 2.29359132e-35]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXz2Y1vIUV3c"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TW3NMCcDMvRi"
      },
      "source": [
        "#Explained variance prints the variance each principal component contributes.\n",
        "#As we can see, the last 5 contribute very little (maybe we can get rid of?)\n",
        "\n",
        "#We also want to check for linearity between the input predictors and the output \n",
        "#If there is high colinearity, then we want to use ridge regression - A variant of lin regression that has regulatization\n",
        "\n",
        "#Correlation indicates strength and direction of a linear relationship. let's use this on the predictors "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPpqUMEHPEWL"
      },
      "source": [
        "## Linear Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1Jdk9FlOrdi"
      },
      "source": [
        "#importing the linear regression library from sklearn \n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdzT-RUFOwag"
      },
      "source": [
        "#initalizing \n",
        "reg0 = LinearRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP3OblI2O1PD",
        "outputId": "9e9aa097-07c8-4467-f626-c7068db27440"
      },
      "source": [
        "#fitting the data to train the model\n",
        "reg0.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPIp5WtMO5Zr",
        "outputId": "b736fe71-9f24-4707-f425-f299ec60fa6f"
      },
      "source": [
        "# R^2 Score to determine the varaiance   \n",
        "reg0.score(X_test,y_test) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:434: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
            "  \"multioutput='uniform_average').\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.1539563533533953e+24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "jSxwuTObd6Gy",
        "outputId": "99fb3a1b-17d4-4dce-b9b3-57eadd893927"
      },
      "source": [
        "#plot of unity where the x axis is the predicted output and y-axis is the expected value \n",
        "#this is similar to the confusion matrix as we want as the points to fit y=x.\n",
        "\n",
        "y_pred = reg0.predict(X_test)\n",
        "plt.scatter(y_pred, y_test)\n",
        "plt.plot(y_test,y_test)\n",
        "plt.xlabel(\"predicted\")\n",
        "plt.ylabel(\"expected\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'expected')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhXrbQ17UXvG",
        "outputId": "9cf7d88a-efb9-4b42-c210-37fd72f210a1"
      },
      "source": [
        "#calculating the mean square error which is quite high for this model, suggesting that the data is not linear \n",
        "mean_squared_error(y_pred=y_pred,y_true=y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.7088583595092018e+25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlw31mV_PR2e"
      },
      "source": [
        "## Random Forest Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__Spw37zPTuX"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zdo5nagPUMC"
      },
      "source": [
        "#initalizing random forest with 50 estimaters and max_depth of 5 to increase the accuracy while making sure to not over-fit the data \n",
        "reg = RandomForestRegressor(n_estimators=500, max_depth=5, random_state=33, n_jobs=6)\n",
        "reg.fit(X_train,y_train)\n",
        "reg.score(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDfC0Bmqd1qb"
      },
      "source": [
        "#plot of unity \n",
        "y_pred = reg.predict(X_test)\n",
        "plt.scatter(y_pred, y_test)\n",
        "plt.plot(y_test,y_test)\n",
        "plt.xlabel(\"predicted\")\n",
        "plt.ylabel(\"expected\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtZdR-CaPkkQ"
      },
      "source": [
        "mean_squared_error(y_pred=reg.predict(X_test),y_true=y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buIEVtinTUxR"
      },
      "source": [
        "[link text](https://)## Deep Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enO0KCchyQIg"
      },
      "source": [
        "#Made my own model using back propagation \n",
        "#Importing relevant libraries for model creation and training \n",
        "#followed this tutoial to implement this model: https://www.tensorflow.org/tutorials/keras/regression\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6DY7nJnVlCE"
      },
      "source": [
        "#initalize a normalizer to scale the input data\n",
        "normalizer = preprocessing.Normalization()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9Wgxt4NVlQ3"
      },
      "source": [
        "#created a model with 5 hidden layers using sigmoid activation because Relu could go to infinity \n",
        "model = keras.Sequential([\n",
        "                          normalizer,\n",
        "    layers.Dense(64, activation='sigmoid'),\n",
        "    layers.Dense(64, activation='sigmoid'),\n",
        "    layers.Dense(128, activation='sigmoid'),\n",
        "    layers.Dense(64, activation='sigmoid'),\n",
        "    layers.Dense(64, activation='sigmoid'),\n",
        "    layers.Dense(2)\n",
        "])\n",
        "# want the model to minimize mean sqaure error, and set the optimizer to adam as it is the most efficient for this case\n",
        "model.compile(loss='mean_squared_error',\n",
        "            optimizer=tf.keras.optimizers.Adam(0.001))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNs2L5YNVtUD"
      },
      "source": [
        "#running 20 epochs to minimize overfitting \n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2, #20% validation split for back propogation \n",
        "    verbose=2, epochs=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKjeB5BzV0cW"
      },
      "source": [
        "#getting the predictions of the model\n",
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZWqYg3MaGKe"
      },
      "source": [
        "#calculating the mean sqaure error. This is significantly lower compared to the other two models implemented \n",
        "mean_squared_error(y_pred=y_pred,y_true=y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hsci2tAKcKtR"
      },
      "source": [
        "plt.scatter(y_pred, y_test)\n",
        "plt.plot(y_test,y_test,'red')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxWAfT63IAf0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}